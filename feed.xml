<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>李清发的技术博客</title>
    <description></description>
    <link>https://liqingfa.github.io/warrior/warrior/</link>
    <atom:link href="https://liqingfa.github.io/warrior/warrior/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 18 Jul 2017 18:03:25 +0800</pubDate>
    <lastBuildDate>Tue, 18 Jul 2017 18:03:25 +0800</lastBuildDate>
    <generator>Jekyll v3.1.1</generator>
    
      <item>
        <title>WWDC2017之Core ML</title>
        <description>&lt;p&gt;Core ML是苹果新推出的，面向开发者的机器学习框架。开发者能够轻松实现实时物体识别、人脸特征点识别、跟踪运动中的物体、文本分析等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://obon901vh.bkt.clouddn.com/wwdc2017-coreml.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​ Core ML 让你将很多机器学习模型集成到你的app中。除了支持层数超过30层的深度学习之外，还支持决策树的融合，SVM（支持向量机），线性模型。由于其底层建立在 Metal 和 Accelerate 等技术上，所以可以最大限度的发挥 CPU 和 GPU 的优势。你可以在移动设备上运行机器学习模型，数据可以不离开设备直接被分析，在一定程度上可以为开发者节省购买服务器的成本。而且该框架让所有的机器学习计算都在iOS设备本地进行,这一点依旧体现出苹果对用户隐私很看重。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://obon901vh.bkt.clouddn.com/wwdc2017-frame.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​	1，Nattural Language processing：自然语言处理。用于语言识别，分词，词性还原，词性判定等。&lt;/p&gt;

&lt;p&gt;​	2，GamePlayKit：游戏制作,构建游戏。用于常见的游戏行为如随机数生成、人工智能、寻路、和代理行为。&lt;/p&gt;

&lt;p&gt;​	3，Vison：苹果在WWDC2017上推出的另一个全新框架，其具有高性能的图像分析和计算机视觉能力，应用于图像和视频分类的场景中识别面孔和检测功能。&lt;/p&gt;

&lt;h2 id=&quot;core-ml&quot;&gt;如何使用Core ML&lt;/h2&gt;

&lt;p&gt;不得不提的是CoreML使用起来非常方便。苹果很聪明的定义了一个标准的模型格式（.mlmodel），提供了流行的框架模型到该格式的 &lt;a href=&quot;https://pypi.python.org/pypi/coremltools&quot;&gt;转换工具&lt;/a&gt; ，比如你可以将你的 &lt;a href=&quot;http://caffe.berkeleyvision.org/&quot;&gt;Caffe&lt;/a&gt; 模型转换成 CoreML 的模型格式。这样就可以利用各个模型的训练阶段，而不像 TensorflowLite 只能使用 Tensorflow 模型。模型训练好了之后，只要拖放到 Xcode 中就可以使用，苹果甚至把接口的Swift代码都给你生成好了，非常方便。&lt;/p&gt;

&lt;h5 id=&quot;step1&quot;&gt;Step1&lt;/h5&gt;

&lt;p&gt;准备好你的模型（.mlmodel）,可以按照上面的方法制作你所需的模型，也可以直接在Apple开发者网站上&lt;a href=&quot;https://developer.apple.com/machine-learning/&quot;&gt;下载&lt;/a&gt;现成的模型：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://obon901vh.bkt.clouddn.com/wwdc2017-mlmodels.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;step2&quot;&gt;Step2&lt;/h5&gt;

&lt;p&gt;​ 新建Project，把格式化的模型文件拖入到项目当中，这里下载的是Places205-GoogLeNet.mlmodel，然后点击该model，可以看到：&lt;/p&gt;

&lt;p&gt;​     &lt;img src=&quot;http://obon901vh.bkt.clouddn.com/wwdc2017-baseinfo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上图可以看到 CoreML Model 分成三部分,第一部分算是基本的描述，第二部分 ModelClass 是对应 Model 生成的 Source 点击 GoogLeNetPlaces (Swift generated source) 末尾的小箭头进入GoogLeNetPlaces.Swift 文件 可以看到对应 Model的类和方法如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GoogLeNetPlacesInput：识别输入参数&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GoogLeNetPlacesInput&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;MLFeatureProvider&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;GoogLeNetPlacesOutput：输出鉴定结果&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GoogLeNetPlacesOutput&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;MLFeatureProvider&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;GoogLeNetPlaces：封装输入输出&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;vi&quot;&gt;@objc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GoogLeNetPlaces&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:NSObject&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;step3&quot;&gt;Step3&lt;/h5&gt;

&lt;p&gt;使用Xcode自动生成的类及方法&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leNetPlaces&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;GoogLeNetPlaces&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;UIImage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;named&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;timg&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vnCoreModel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;try!&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VNCoreMLModel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leNetPlaces&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vnCoreMLRequest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VNCoreMLRequest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vnCoreModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;VNRequest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Error&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;?)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;​&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;guard&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as?&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;VNClassificationObservation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;​&lt;/span&gt;      &lt;span class=&quot;n&quot;&gt;fatalError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Requset Error&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;​&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;​&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classification&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;​&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classification&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confidence&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;​&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classification&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;identifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;​&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classification&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confidence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;​&lt;/span&gt;     &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;​&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vnImageRequestHandler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VNImageRequestHandler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;cgImage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cgImage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;guard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;try?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vnImageRequestHandler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vnCoreMLRequest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;nil&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;fatalError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Error!&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;这里使用了&lt;a href=&quot;https://developer.apple.com/documentation/vision&quot;&gt;Vision&lt;/a&gt;库中的VNCoreMLModel , VNCoreMLRequest , VNImageRequestHandler。&lt;/p&gt;

&lt;h5 id=&quot;step4&quot;&gt;step4&lt;/h5&gt;

&lt;p&gt;下面来看一下识别结果如何：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://obon901vh.bkt.clouddn.com/wwdc2017-result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;一些疑问&lt;/h2&gt;

&lt;p&gt;1，在模型训练阶段，在尽可能不收集用户数据的前提下，如何优化模型？既使像苹果在去年的 WWDC 上宣称的「我们不需要收集所有用户拍的照片，才知道山长什么样子」，也依然不能回避的事实是，在模型的调优方面，少不了大量的数据支撑。想从 95% 的水平提升到 99% 的水平，数据还是不可缺少的一环。&lt;/p&gt;

&lt;p&gt;2，在模型应用阶段，如何做到尽可能在设备本地完成处理？早期受限于设备的性能和功耗，特别是移动设备的电量问题，许多公司选择将数据上传至云端后，由云端服务器来进行运算，只将结果返回给终端设备。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;总结下来，苹果的目标，就是在尽可能不收集用户数据的基础上，也能调校出足够好用的模型，同时尽可能只在消费者的设备本地运用模型进行计算处理。而对从业者来说，如何利用好这一优秀条件创造出更好的应用也至关重要。&lt;/p&gt;

</description>
        <pubDate>Mon, 26 Jun 2017 20:00:00 +0800</pubDate>
        <link>https://liqingfa.github.io/warrior/warrior/blog/2017/WWDC2017%E4%B9%8BCore-ML/</link>
        <guid isPermaLink="true">https://liqingfa.github.io/warrior/warrior/blog/2017/WWDC2017%E4%B9%8BCore-ML/</guid>
        
        
        <category>WWDC</category>
        
      </item>
    
  </channel>
</rss>
